//MKV格式视频解码为yuv和h264

#include <stdio.h>
#include <stdlib.h>
extern "C" {
#include "libavcodec/avcodec.h"
	//封装格式处理
#include "libavformat/avformat.h"
	//像素处理
#include "libswscale/swscale.h"
#include "libavutil/imgutils.h"
};
//编码


//#pragma warning(disable : 4996)
int main1()
{
	//获取输入输出文件名
	const char *input = "decode.mkv";
	const char *output = "decode.yuv";
	const char *output1 = "decode.h264";

	//1.注册所有组件
	av_register_all();

	//封装格式上下文，统领全局的结构体，保存了视频文件封装格式的相关信息
	AVFormatContext *pFormatCtx = avformat_alloc_context();

	//2.打开输入视频文件
	if (avformat_open_input(&pFormatCtx, input, NULL, NULL) != 0)
	{
		printf("%s", "无法打开输入视频文件");
		return 0;
	}

	//3.获取视频文件信息
	if (avformat_find_stream_info(pFormatCtx, NULL) < 0)
	{
		printf("%s", "无法获取视频文件信息");
		return 0;
	}

	//获取视频流的索引位置
	//遍历所有类型的流（音频流、视频流、字幕流），找到视频流
	int v_stream_idx = -1;
	int i = 0;
	//number of streams
	for (; i < pFormatCtx->nb_streams; i++)
	{
		//流的类型
		if (pFormatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO)
		{
			v_stream_idx = i;
			break;
		}
	}

	if (v_stream_idx == -1)
	{
		printf("%s", "找不到视频流\n");
		return 0;
	}
	//只有知道视频的编码方式，才能够根据编码方式去找到解码器
	//获取视频流中的编解码上下文
	AVCodecContext *pCodecCtx;
	pCodecCtx = avcodec_alloc_context3(NULL);
	if (pCodecCtx == NULL) {
		printf("Could not allocate AVCodecContext\n");
		return -1;
	}
	avcodec_parameters_to_context(pCodecCtx, pFormatCtx->streams[v_stream_idx]->codecpar);
	AVCodec *pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
	if (pCodec == NULL) {
		printf("Codec not found.\n");
		return -1;
	}

	//4.根据编解码上下文中的编码id查找对应的解码
	//AVCodec *pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
	if (pCodec == NULL)
	{
		printf("%s", "找不到解码器\n");
		return 0;
	}

	//5.打开解码器
	if (avcodec_open2(pCodecCtx, pCodec, NULL)<0)
	{
		printf("%s", "解码器无法打开\n");
		return 0;
	}

	//输出视频信息
	printf("视频的文件格式：%s", pFormatCtx->iformat->name);
	printf("视频时长：%d", (pFormatCtx->duration) / 1000000);
	printf("视频的宽高：%d,%d", pCodecCtx->width, pCodecCtx->height);
	printf("解码器的名称：%s", pCodec->name);

	//准备读取
	//AVPacket用于存储一帧一帧的压缩数据（H264）
	//缓冲区，开辟空间
	AVPacket *packet = (AVPacket*)av_malloc(sizeof(AVPacket));

	//AVFrame用于存储解码后的像素数据(YUV)
	//内存分配
	AVFrame *pFrame = av_frame_alloc();
	//YUV420
	AVFrame *pFrameYUV = av_frame_alloc();
	//只有指定了AVFrame的像素格式、画面大小才能真正分配内存
	//缓冲区分配内存
	uint8_t *out_buffer = (uint8_t *)av_malloc(av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height, 1));
	//初始化缓冲区
	av_image_fill_arrays(pFrameYUV->data, pFrameYUV->linesize, out_buffer, AV_PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height, 1);


	//用于转码（缩放）的参数，转之前的宽高，转之后的宽高，格式等
	struct SwsContext *sws_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix_fmt,
		pCodecCtx->width, pCodecCtx->height, AV_PIX_FMT_YUV420P,
		SWS_BICUBIC, NULL, NULL, NULL);
	int got_picture, ret;

	FILE *fp_yuv, *fp_h264;
	fopen_s(&fp_yuv, output, "wb+");
	fopen_s(&fp_h264, output1, "wb+");

	int frame_count = 0;

	//6.一帧一帧的读取压缩数据
	while (av_read_frame(pFormatCtx, packet) >= 0)
	{
		//只要视频压缩数据（根据流的索引位置判断）
		if (packet->stream_index == v_stream_idx)
		{

			fwrite(packet->data, 1, packet->size, fp_h264);
			//7.解码一帧视频压缩数据，得到视频像素数据
			ret = avcodec_send_packet(pCodecCtx, packet);
			got_picture = avcodec_receive_frame(pCodecCtx, pFrame);


			if (ret < 0)
			{
				printf("%s", "解码错误");
				return 0;
			}

			//为0说明解码完成，非0正在解码
			if (!got_picture)
			{
				//AVFrame转为像素格式YUV420，宽高
				//2 6输入、输出数据
				//3 7输入、输出画面一行的数据的大小 AVFrame 转换是一行一行转换的
				//4 输入数据第一列要转码的位置 从0开始
				//5 输入画面的高度
				sws_scale(sws_ctx, pFrame->data, pFrame->linesize, 0, pCodecCtx->height,
					pFrameYUV->data, pFrameYUV->linesize);

				//输出到YUV文件
				//AVFrame像素帧写入文件
				//data解码后的图像像素数据（音频采样数据）
				//Y 亮度 UV 色度（压缩了） 人对亮度更加敏感
				//U V 个数是Y的1/4
				int y_size = pCodecCtx->width * pCodecCtx->height;
				fwrite(pFrameYUV->data[0], 1, y_size, fp_yuv);
				fwrite(pFrameYUV->data[1], 1, y_size / 4, fp_yuv);
				fwrite(pFrameYUV->data[2], 1, y_size / 4, fp_yuv);

				frame_count++;
				printf("解码第%d帧\n", frame_count);
			}
		}

		//释放资源
		av_packet_unref(packet);

	}
	
	fclose(fp_yuv);
	fclose(fp_h264);

	av_frame_free(&pFrame);

	avcodec_close(pCodecCtx);

	avformat_free_context(pFormatCtx);

	getchar();
	return 0;

}